---
tags: []
layout: post
title: 几种常见的推荐算法和模型
category: 
keywords: 几种有意思的推荐算法总结,slope one,余弦相似性,隐语义模型,内容模型,广告推荐算法
description: 整理了几种比较简单有意思的推荐算法，希望可以对有兴趣的童鞋有所帮助
---
## 导语

广告推荐算法从广义上应该是推荐系统的一种，最近几年大数据概念的流行，推荐系统越来越重要，相应的模型和方法也非常多。

无疑做推荐系统最好的选择的就是机器学习，现在也有很多成熟的机器学习框架如torch等，但此篇文章的重点在于整理一些可以尽量不依赖第三方框架可以自行实现的方案。或者说是介绍几种比较有意思的推荐算法或思路吧。

一些复杂的推荐算法不免涉及到一些高等数学和机器学习相关的知识，在这里我尽量简单描述，公式可以无视它，尽量理解思想。

本文中的若干图片剽窃于互联网，侵删。



## 几种常见的推荐算法/模型
### Slope one 
*最简单有效的推荐算法之一*

Slope One算法是一种基于评分的预测算法,本质上也是一种基于项目预测的算法。该算法是用一种简单的线性回归模型f(x) = ax + b进行预测。该算法易于实现,计算速度快,可扩展性好,同时对数据稀疏性有较好的适应性。

![](http://7xvhwc.com1.z0.glb.clouddn.com/image2015-5-14%2015-36-3.png)


一个简单的场景：下表是用户与应用评分关系表。表示一个用户对一个应用的喜好程度。

||App 1|App 2|App 3
| :------------ | :------------ |
|User 1|5|3|2
|User 2|3|4	|?
|User 3|?|2|5

我们这里喜好程度用`0-5`数值表示，`0`最不喜欢，`5`最喜欢。`?` 表示没安装过，不知道喜好程度。

数值怎么算出来的？好吧，我这里只简单罗列一种可能的量化方式，不代表一定要这么计算：

|用户数据|喜好程度值
| :------------ | :------------ |
|最近7天内DAU>3 |5
|最近7天内DAU>0|4
|最近10天内DAU>0|3
|最近14天内DAU>0|2
|最近30天内DAU>0|1
|已卸载|0


我们在这个场景下，假如我们要推导User3对App1的喜好程度，以决定是不是要给TA推广相应的应用。

怎么做？Slope One就两步。

1.计算出所有不同应用之间的**平均值偏差**。

|所有应用的两两组合|计算方法|平均值偏差
| :------------ | :------------ |
|App 1 & App 2|[(5-3) + (3-4)]/2|0.5
|App 1 & App 3|[(5-2)]/1|3
|App 2 & App 3|[(3-2)+(2-5)]/2|-1


其中，Sj,i(x)表示同时对App i和j喜好程度的user set，而 card(Sj,i(c))表示user set中的user数。 devj,i表示两个App i和j 的平均值偏差，Uj 和Ui表示用户x对App j和i的喜好程度。



2.计算目标用户对目标应用的预估分数。

因为User 3给App 2评价过，分值为2分，所以我们可以根据物品2来预测，其中物品2和物品1的偏差是0.5， 也就是 0.5 + 2 = 2.5；
因为User 3也给App 3评价过，分值为5分，而物品3和物品1的偏差是3， 所以也有 3 + 5 = 8；
综合起来，我们可以预测User 3也给App 1的评分是 (2.5+8)/2 = 5.25。



在这里我们定义最高分5分，最低分0分，超过5分的统一记5分，所以，我们预估User 3 对 App1的 喜好程度 是5分；

是不是很简单呢？

其实这里只是最简单的一种形式，在真实的应用中，还需要考虑很多复杂的情况，例如，加权处理，过适处理，如何进行分布式计算 等。



### Cosine formula
*余弦相似性*

此算法是通过使用余弦公式来量化并判断两个User的相似性。

继续举栗子。还是用户与应用评分关系表。我们对评分做一下更改。 

 ||App 1|App 2|App 3
 | :------------ | :------------ |
|User 1|3|0|0
|User 2|5|1|0
|User 3|0|3|3


我们可以看出来，User 1 和 User 2 二位品味接近，User 3 和他们很不一样。

那么问题来了，说User 1 和 User 2 相似，到底有多相似，如何量化？

我们把三个应用想象成三维空间的三个维度，用户对每个App的喜欢程度即该维度上的坐标。

那么每个人的总体口味就是一个多维空间中的向量，User 1是 (3,0,0)，User 2是(5,1,0)，User 3是(0,3,3)

我们可以用向量夹角的余弦值来表示两个向量的相似程度， 0度角(表示两人完全一致)的余弦是1， 180%角(表示两人截然相反)的余弦是-1。

那么我们算算每个用户两两之间各自的夹角是多少？

![](https://wikimedia.org/api/rest_v1/media/math/render/svg/a71c4add4abded66efd42b202c76f6a59944a587)

|用户组	|坐标组	|cosine值（相似度）
 | :------------ | :------------ |
|User 1 & User 2|	(3,0,0) , (5,1,0)	|0.98
|User 1 & User 3|	(3,0,0) , (0,3,3)	|0
|User 2 & User 3|	(5,1,0) , (0,3,3)	|0.14

这里的计算结果还是跟我们直观上的感受是一样，User 1 和 User 2的品味接近，计算出来的结果也非常接近于1。

等等！User 1 和 User 3 的口味很明显是截然相反的，为什么他们的值等于0而不是-1？

原因很简单，因为我们的评分机制没有引进负分，在正整数的坐标空间中，两个向量的最大夹角不可能超过90度，故余弦值最小为0。

真实环境中几千上万个应用的情况下怎么算？

这里实际上为了简便，我选择了3维来讲解，因为人能理解的最高维度就是3维，但这不代表多维的坐标系不存在，只是我们人类作为3维生物无法理解超过3维的情况。

事实上，N维的处理和3维的计算步骤是一样的，只不过多一些运算而已。

计算出结果后，我们就可以找出N个和目标用户最接近的用户，他们有哪些应用目标用户没有安装的，就可以推荐了。（其实这个步骤也很耗时，必要时需要再进行算法上的优化处理，这里就不单独再讲了，其中关于此公式的推导过程，有兴趣的童鞋可以参考这里：http://blog.csdn.net/u012160689/article/details/15341303 ）


### Latent factor model
*隐语义模型 / 潜在因子模型*

此算法是通过矩阵分解的最优解寻找隐藏因子。

这个模型的每个步骤都会涉及到一些具体的算法，在这里我只说一下这个模型的大体实现方式，不再具体讲解每个步骤的具体计算方式。

还是要举栗子。不过我们这次是要稍微换个角度来考虑问题。

下表是用户与不同类型的App的兴趣度关系表。数值范围0～1 。其中数值越大，代表用户对应用兴趣越高，数值越小代表用户对应用兴趣越低。

我们给这个表格取名：用户-潜在因子矩阵

 ||阅读类|社交类|游戏类
  | :------------ | :------------ |
|张三|0.9|0.2|0.1
|李四	|0.2|0.6|0.1
|王五	|0|0.3|0.7
 

以及App和类型关联度表。数值范围0～1 。其中的数值越大，代表应用和类型越匹配；数值越小，代表应用和类型越不匹配。

我们给这个表格取名：应用-潜在因子矩阵

 ||阅读类	|社交类|	游戏类
| :------------ | :------------ |
|App 1	|0.9	|0.5	|0.1
|App 2	|0.1	|0.2	|0.8
|App 3	|0.3	|0.7	|0.2
|App 4	|0.2	|0.5	|0.6

那么，利用这2个矩阵，我们如果要计算一下 张三 对 App 1 的兴趣度是多少呢，如何计算？

我用汉语写一下公式：

张三 对 App 1 的兴趣度 = 张三对阅读类的兴趣度 x App1在阅读类的关联度 + 张三对社交类的兴趣度 x App1在社交类的关联度 + 张三对游戏类的兴趣度 x App1在游戏类的关联度

那么计算结果是：0.9×0.9+0.2×0.5+0.1×0.1= 0.83

我们计算一下王五对App 1的兴趣度：

0×0.9 + 0.3×0.5 + 0.7×0.1 = 0.22

嗯嗯，看起来很简单。但其实真正的问题是：

用户-潜在因子矩阵 和 应用-潜在因子矩阵 是怎么来的？

人为划分？

如果是UGC可以让用户提交TAG，或者编辑整理主流的TAG；

但其实这应该是有一些问题的，比如划分的规则是怎么样的？因为人都是有主观意识的，每个人的划分规则都不太一样，如何控制？划分粒度如何控制？

如果是非人为，一般是通过矩阵分解（SVG）的方式。

这里假设我们已经有了用户的原始行为数据（数值大体表示用户对应用的使用频率，定义可以参考Slope one的例子）。事实上，这是一个非常稀疏的矩阵。

我们给他取个名字叫 原始矩阵。

原始矩阵标识了用户对每个APP的喜好程度。

如何利用这个矩阵去找潜在因子呢？一般使用矩阵的UV分解。也就是将上面的评分矩阵分解为两个低维度（具体factors的维度可以自行定义，例如下图是3维）的矩阵，用Q和P两个矩阵的乘积去估计实际的评分矩阵，

而且我们希望估计的评分矩阵和实际的评分矩阵不要相差太多，也就是说，通过一系列的计算，寻找2个矩阵Q和Pt（P的转置矩阵）使得Q×Pt最大程度的接近原始矩阵。

得出的最优解就是我们需要的 用户-潜在因子矩阵 （Q）和 应用-潜在因子矩阵（Pt）。

那么如何进行计算？

目前主流的算法是梯形下降算法，因为这个计算方式非常复杂，就不在这里列出了。具体计算方式可以看这里：http://blog.csdn.net/harryhuang1990/article/details/9924377



### Content based model
*关键词模型* 

这是一种在互联网广告中广泛使用的推荐模型。

其实这种模型和隐语义模型很像，区别主要是一个是通过求导迭代运算寻找矩阵分解的最优解，一个是通过字符串提取关键词来寻找最高关联度。

还是通过例子来说吧。

下表是某款安全应用的标题和描述（内容从Goolgle Play抓取），然后利用分词算法可以提取关键词（主要是名词）和对应的出现次数。

|关键词	|出现次数
  | :------------ | :------------ |
|私密|4
|保密	|3
|加密	|1
|隐藏	|1
|照片	|1
|视频	|1
|短信	|1
|安卓	|1


有些词是我们不感兴趣的，可以过滤掉。

针对所有的已知应用如法炮制一番，我们可以得到下表

我们叫 **应用词频表**

|| 安全	|秘密	|交友	|聊天
| :------------ | :------------ |
|某管家	|0	|4	|0	|0
|某助手	|3	|0	|0	|0
|微信	|0	|1	|2	|3
|QQ	|1	|0	|1	|2


注意：这里的（安全/秘密/交友/聊天）是通过分词算法提取的关键词，数字是每个应用相应关键词的出现次数。

这个表格是不是很熟悉？对了，跟前面讲到的  应用-潜在因子矩阵 很像，只不过，这里不是潜在因子，而是关键词。

那每个应用的描述内容从哪里来的呢？

其实来源有很多，这里我们简单处理，假设是从应用市场抓取的标题和简介内容。写个爬虫把我们感兴趣的应用的描述信息抓下来，并分词，就可以得到应用词频表了。

好了，应用词频表 有了，用户和不同词频的关联关系 又如何获取呢？

在互联网条件下，其实很好实现，可以利用Cookie追踪或者搜索关键词直接处理。

在移动互联网中，用户的搜索记录对我们基本是不可见的，所以一种可行的方式就是针对用户已安装列表（尤其是用户活跃使用的应用要加权处理）做词频汇总。

我们可以获取到以下原始数据：

 ||安装的应用	|最近频繁打开的应用
 | :------------ | :------------ |
|张三	|某管家 / QQ	|QQ
|李四	|某助手 / 微信	|某助手
|王五	|微信 / QQ	|微信

那么，我们计算 张三 对于 安全 这个关键词的兴趣度是多少呢？ 假设我们对最近频繁打开的应用的权值设置为2

某管家中安全的词频 + QQ中安全的词频 + QQ中安全的词频x权值 = 0+1+1x2 = 3

同理，我们计算一下李四 对 安全这个关键词的兴趣度多少呢？

某助手中安全的词频 + 微信中安全的词频 + 某助手中安全的词频x权值 = 3+0+3x2 = 9

于是，利用这种方法，我们可以得到下表：

 ||安全	|秘密	|交友	|聊天
| :------------ | :------------ |
|张三	|3	|4	|3	|6
|李四	|9	|1	|2	|3
|王五	|1	|3	|7	|11

有了这张表，我们就能针对性的对每个用户下发他们感兴趣的广告了。

例如，很明显王五对’聊天‘这个词感兴趣，那么，就给他下发出现’聊天‘这个词频高的应用就行了。





## 验证方法
算法和模型有了，如何验证他们的有效性？

要通过一段时间的 大样本对照实验 来评估。

### 关键点：

样本一定要足够大；

建议分组对照，例如分为以下几组：静态数据组  随机数据组  推荐算法组 

静态数据组 所有用户请求的广告都一样，且每次都不变化；

随机数据组 所有用户请求的广告都不一样，且每次都变化；

推荐算法组 所有用户请求的广告按算法进行评估下发；

对照实验要持续一段时间，以便获得稳定的数据；

实验结束后，比较每组的点击率就知道是否有效了；



## 总结
真正的推荐系统不是简单的一两个算法，而是基于多种算法的综合决策系统；

推荐模型不是绝对的，要看具体推荐的数据分布，对A而言推荐度很高的算法不一定适合B；

即使是一个算法也有很多参数需要综合考虑；

算法的有效性一定要通过真实数据的检验；

高效率的推荐算法不是一次性建立起来的，而是通过不同的调优参数/对照实验/查看结果/再调优参数/再对照实验...这个循环过程来实现的；